# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ app.py  (drop-in version) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
"""
Mumblr backend â€” Flask + openai-python â‰¥ 1.4

â€¢ Works with the new OpenAI client (openai.ChatCompletion deprecated).
â€¢ Supports single-line 'transcription' or multi-line 'recordings'.
â€¢ Reads model / temperature / seed from env vars.
â€¢ CORS enabled so any front-end (Lovable, local dev) can call it.
"""

from __future__ import annotations
import os
from typing import Any, List

from flask import Flask, request, jsonify
from flask_cors import CORS
from openai import OpenAI, OpenAIError

# â”€â”€ configuration â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")            # (required)
OPENAI_MODEL   = os.getenv("OPENAI_MODEL", "gpt-4o-mini")
TEMPERATURE    = float(os.getenv("TEMPERATURE", "0.4"))
SEED_STR       = os.getenv("SEED")                      # optional
SEED           = int(SEED_STR) if SEED_STR else None

SYSTEM_PROMPT = """
You are Mumblr, an AI lyric-finisher.

When the user sends JSON it will contain:
  â€¢ transcription â€“ single raw line from humming/singing          (string)
  â€¢ recordings    â€“ an array of raw lines (if provided)           (list[str])
  â€¢ mood          â€“ e.g. Breakup & Heartbreak, Party & Celebration
  â€¢ section       â€“ Verse, Chorus, Bridge, etc.
  â€¢ story         â€“ OPTIONAL extra context or scene

You must:
1. Keep **each raw lineâ€™s core words** (donâ€™t lose key nouns/verbs).
2. Improve rhyme & rhythm; you may tweak tense or add small fillers
   (â€œohâ€, â€œyeahâ€) **but do NOT merge or drop lines**.
3. Return **exactly** the same number of numbered lines, nothing else,
   each on its own line.

Respond with lyrics **only** (no commentary, no JSON).
"""

# â”€â”€ OpenAI client â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
client = OpenAI(api_key=OPENAI_API_KEY)

# â”€â”€ Flask setup â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
app = Flask(__name__)
CORS(app)                                   # allow any Origin by default


@app.get("/")
def health() -> tuple[str, int]:
    """Renderâ€™s health-check route."""
    return "Mumblr API is live ðŸŽ¤", 200


@app.post("/mumblr")
def generate_lyrics() -> tuple[Any, int, dict[str, str]]:
    """Generate finished lyrics from raw recordings."""
    try:
        data = request.get_json(force=True) or {}

        # â”€â”€ pull fields â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        recordings: List[str] = data.get("recordings") or []
        transcription = str(data.get("transcription", "")).strip()
        mood          = str(data.get("mood", "")).strip()
        section       = str(data.get("section", "")).strip()
        story         = str(data.get("story", "")).strip()

        # normalise â†’ ensure we always have a list of raw lines
        if isinstance(recordings, list) and recordings:
            raw_lines = [str(x).strip() for x in recordings if x]
        elif transcription:
            raw_lines = [transcription]
        else:
            return jsonify(error="No transcription or recordings supplied"), 400

        mumble_block = "\n".join(f"- {l}" for l in raw_lines)

        prompt = f"""
### Raw takes
{mumble_block}

### Requirements (DO NOT break these)
1. Keep each takeâ€™s core words.
2. Fix rhyme & rhythm, add tiny fillers if needed.
3. Return exactly {len(raw_lines)} numbered lines â€¦ nothing else.

### Context
Mood   : {mood or '(none)'}
Section: {section or '(none)'}
Story  : {story or '(none)'}
"""

        # â”€â”€ OpenAI call â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        resp = client.chat.completions.create(
            model       = OPENAI_MODEL,
            messages    = [
                {"role": "system", "content": SYSTEM_PROMPT.strip()},
                {"role": "user",   "content": prompt.strip()},
            ],
            temperature = TEMPERATURE,
            seed        = SEED,
        )

        lyrics = resp.choices[0].message.content.strip()
        return lyrics, 200, {"Content-Type": "text/plain"}

    except OpenAIError as oe:
        app.logger.error("OpenAI error: %s", oe)
        return jsonify(error=str(oe)), 500
    except Exception as e:
        app.logger.exception("Unexpected error")
        return jsonify(error="Server error"), 500


# â”€â”€ run locally (Render ignores this when using gunicorn) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if __name__ == "__main__":
    app.run(debug=True, port=int(os.getenv("PORT", "5000")))
